{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "849aa16d",
   "metadata": {},
   "source": [
    "# Title: PyTorch_AMP_Training_Loop_with_EarlyStopping\n",
    "## Description: PyTorch ëª¨ë¸ í•™ìŠµ ì‹œ FP16(Mixed Precision)ì„ ì‚¬ìš©í•˜ì—¬ ë©”ëª¨ë¦¬ì™€ ì†ë„ë¥¼ ìµœì í™”í•˜ê³ , Early Stoppingì„ í†µí•´ ê³¼ì í•©ì„ ë°©ì§€í•˜ëŠ” í‘œì¤€ í•™ìŠµ íŒŒì´í”„ë¼ì¸.\n",
    "## Input: \n",
    " - model (nn.Module): í•™ìŠµí•  PyTorch ëª¨ë¸\n",
    " - optimizer (torch.optim): ì˜µí‹°ë§ˆì´ì €\n",
    " - train_loader (DataLoader): í•™ìŠµ ë°ì´í„° ë¡œë”\n",
    " - val_loader (DataLoader): ê²€ì¦ ë°ì´í„° ë¡œë”\n",
    " - scheduler (lr_scheduler): í•™ìŠµë¥  ìŠ¤ì¼€ì¤„ëŸ¬ (Optional)\n",
    " - device (torch.device): í•™ìŠµ ì¥ì¹˜ (CPU/GPU)\n",
    " - epochs (int): ìµœëŒ€ ì—í­ ìˆ˜\n",
    "## Output: \n",
    " - best_model (nn.Module): ê²€ì¦ ì ìˆ˜ê°€ ê°€ì¥ ë†’ì€ ëª¨ë¸ì˜ state_dictê°€ ë¡œë“œëœ ê°ì²´\n",
    "## Check Point: \n",
    " - `torch.cuda.amp`ë¥¼ ì‚¬ìš©í•˜ë¯€ë¡œ GPU í™˜ê²½ ê¶Œì¥.\n",
    " - í‰ê°€ ì§€í‘œë¡œ F1 Score(Macro)ë¥¼ ì‚¬ìš©í•˜ë¯€ë¡œ `sklearn` ë¼ì´ë¸ŒëŸ¬ë¦¬ í•„ìš”."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee10a6a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "from copy import deepcopy\n",
    "from tqdm.auto import tqdm\n",
    "from torch.amp import GradScaler, autocast\n",
    "from sklearn.metrics import f1_score\n",
    "\n",
    "# [Block 1] Early Stopping Class\n",
    "class EarlyStopping:\n",
    "    \"\"\"\n",
    "    ê²€ì¦ ì†ì‹¤ì´ ê°œì„ ë˜ì§€ ì•Šì„ ë•Œ í•™ìŠµì„ ì¡°ê¸° ì¢…ë£Œí•˜ê³  ìµœì ì˜ ëª¨ë¸ì„ ì €ì¥í•˜ëŠ” ìœ í‹¸ë¦¬í‹°\n",
    "    \"\"\"\n",
    "    def __init__(self, patience=5, verbose=True, path=\"best_model_earlystop.pth\"):\n",
    "        self.patience = patience\n",
    "        self.verbose = verbose\n",
    "        self.path = path\n",
    "        self.counter = 0\n",
    "        self.best_score = None\n",
    "        self.early_stop = False\n",
    "        self.best_model_wts = None\n",
    "\n",
    "    def __call__(self, score, model):\n",
    "        if self.best_score is None:\n",
    "            self.save_checkpoint(score, model)\n",
    "            self.best_score = score\n",
    "        elif score <= self.best_score:\n",
    "            self.counter += 1\n",
    "            if self.verbose:\n",
    "                print(f\"ğŸ” EarlyStopping counter: {self.counter} / {self.patience}\")\n",
    "            if self.counter >= self.patience:\n",
    "                self.early_stop = True\n",
    "        else:\n",
    "            self.save_checkpoint(score, model)\n",
    "            self.best_score = score\n",
    "            self.counter = 0\n",
    "\n",
    "    def save_checkpoint(self, score, model):\n",
    "        if self.verbose:\n",
    "            if self.best_score is not None and self.best_score != score:\n",
    "                print(f\"Validation score improved ({self.best_score:.4f} --> {score:.4f}). Saving model...\")\n",
    "            else:\n",
    "                print(f\"Validation score set to {score:.4f}. Saving model...\")\n",
    "        torch.save(model.state_dict(), self.path)\n",
    "\n",
    "# [Block 2] Validation Logic\n",
    "def validation(model, criterion, val_loader, device):\n",
    "    \"\"\"\n",
    "    ê²€ì¦ ë°ì´í„°ì…‹ì— ëŒ€í•œ í‰ê°€ë¥¼ ìˆ˜í–‰ (AMP ë¯¸ì ìš©, No Grad)\n",
    "    \"\"\"\n",
    "    model.eval()\n",
    "    val_loss = []\n",
    "    preds, true_labels = [], []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for imgs, labels in tqdm(val_loader, desc=\"Validating\", leave=False):\n",
    "            imgs = imgs.to(device)\n",
    "            labels = labels.to(device)\n",
    "\n",
    "            # Inference ì‹œì—ëŠ” autocastë§Œ ì ìš© (Scaler ë¶ˆí•„ìš”)\n",
    "            with autocast():\n",
    "                pred = model(imgs)\n",
    "                loss = criterion(pred, labels)\n",
    "\n",
    "            # ê²°ê³¼ ìˆ˜ì§‘ (GPU -> CPU -> List)\n",
    "            preds += pred.argmax(1).detach().cpu().numpy().tolist() #ê° ì´ë¯¸ì§€ í™•ë¥  ë¶„í¬ì—ì„œ ê°€ì¥ ë†’ì€ ì¸ë±ìŠ¤ ì„ íƒ í›„ list ê¹Œì§€\n",
    "            true_labels += labels.detach().cpu().numpy().tolist()\n",
    "            val_loss.append(loss.item())\n",
    "\n",
    "    _val_loss = np.mean(val_loss)\n",
    "    _val_score = f1_score(true_labels, preds, average='macro')\n",
    "    \n",
    "    return _val_loss, _val_score\n",
    "\n",
    "# [Block 3] Main Training Loop\n",
    "def train_pipeline(model, optimizer, train_loader, val_loader, scheduler, device, epochs, early_stopping):\n",
    "    \"\"\"\n",
    "    AMPì™€ GradScalerë¥¼ ì ìš©í•œ ë©”ì¸ í•™ìŠµ ë£¨í”„\n",
    "    \"\"\"\n",
    "    model.to(device)\n",
    "    \n",
    "    # Label Smoothing ì ìš©ëœ Loss ì‚¬ìš© (ì¼ë°˜í™” ì„±ëŠ¥ í–¥ìƒ)\n",
    "    criterion = nn.CrossEntropyLoss(label_smoothing=0.05).to(device)\n",
    "    \n",
    "    # FP16 í•™ìŠµì„ ìœ„í•œ Scaler ì´ˆê¸°í™”\n",
    "    scaler = GradScaler()\n",
    "    \n",
    "    for epoch in range(1, epochs + 1):\n",
    "        model.train()\n",
    "        train_loss = []\n",
    "        \n",
    "        loop = tqdm(train_loader, desc=f\"Epoch {epoch}\", leave=True)\n",
    "        for imgs, labels in loop:\n",
    "            imgs = imgs.to(device)\n",
    "            labels = labels.to(device)\n",
    "\n",
    "            optimizer.zero_grad() # [ì§€ì‹] : íŒŒì´í† ì¹˜ëŠ” ê¸°ë³¸ì ìœ¼ë¡œ gradientë¥¼ ëˆ„ì  í•¨.\n",
    "            # ì´ë¥¼ ë°©ì§€í•˜ê¸° ìœ„í•´ gradientë¥¼ ì´ˆê¸°í™”\n",
    "\n",
    "            # Mixed Precision Forward Pass\n",
    "            with autocast(): # [autocast] : ì´ ì•ˆì—ì„œ ì¼ì–´ë‚˜ëŠ” ê³„ì‚°ì€ 16ë¹„íŠ¸ì™€ 32ë¹„íŠ¸ë¥¼ ì„ì–´ì„œ ê³„ì‚°í•¨. --> ë©”ëª¨ë¦¬ ì ˆë°˜ìœ¼ë¡œ ì¤„ì´ê¸° ê°€ëŠ¥\n",
    "                outputs = model(imgs)\n",
    "                loss = criterion(outputs, labels)\n",
    "\n",
    "            # Scaled Backward Pass ( gradient scaling )\n",
    "            scaler.scale(loss).backward() # loss ê°’ì„ scale í•´ì„œ backward ìˆ˜í–‰ --> gradient vanishing ë°©ì§€\n",
    "            scaler.step(optimizer) # ë»¥íŠ€ê¸° í•œ gradientë¥¼ ë‹¤ì‹œ ì›ë˜ëŒ€ë¡œ ì¤„ì—¬ì„œ optimizer ì—…ë°ì´íŠ¸\n",
    "            scaler.update()\n",
    "\n",
    "            train_loss.append(loss.item())\n",
    "            loop.set_postfix(loss=loss.item())\n",
    "\n",
    "        # Validation Step\n",
    "        _val_loss, _val_score = validation(model, criterion, val_loader, device)\n",
    "        _train_loss = np.mean(train_loss)\n",
    "\n",
    "        print(f'Epoch [{epoch}], Train Loss: {_train_loss:.5f}, Val Loss: {_val_loss:.5f}, Val F1: {_val_score:.5f}')\n",
    "\n",
    "        # Scheduler Step\n",
    "        if scheduler is not None:\n",
    "            scheduler.step(_val_score)\n",
    "\n",
    "        # Early Stopping Check\n",
    "        early_stopping(_val_score, model)\n",
    "        if early_stopping.early_stop:\n",
    "            print(\"Early stopping triggered.\")\n",
    "            break\n",
    "\n",
    "    # Load Best Model Weights\n",
    "    model.load_state_dict(torch.load(early_stopping.path))\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2c4db1a",
   "metadata": {},
   "source": [
    "## How to Use\n",
    "1. **ë°ì´í„° ì¤€ë¹„**: `CustomDataset`ê³¼ `DataLoader`ë¥¼ ì‚¬ìš©í•˜ì—¬ `train_loader`, `val_loader`ë¥¼ ë¯¸ë¦¬ ì •ì˜í•˜ì„¸ìš”.\n",
    "2. **ëª¨ë¸ ë° ì˜µí‹°ë§ˆì´ì € ì •ì˜**: `timm` ë“±ì„ ì‚¬ìš©í•´ ëª¨ë¸ì„ ìƒì„±í•˜ê³  `optimizer`, `scheduler`ë¥¼ ì„¤ì •í•˜ì„¸ìš”.\n",
    "3. **í•™ìŠµ ì‹¤í–‰**:\n",
    "    ```python\n",
    "    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "    early_stopping = EarlyStopping(patience=5, path=\"my_best_model.pth\")\n",
    "    \n",
    "    trained_model = train_pipeline(\n",
    "        model=model,\n",
    "        optimizer=optimizer,\n",
    "        train_loader=train_loader,\n",
    "        val_loader=val_loader,\n",
    "        scheduler=scheduler,\n",
    "        device=device,\n",
    "        epochs=100,\n",
    "        early_stopping=early_stopping\n",
    "    )\n",
    "    ```\n",
    "\n",
    "## Troubleshooting\n",
    "- **NaN Loss ë°œìƒ**: `GradScaler` ì‚¬ìš© ì‹œ í•™ìŠµë¥ (LR)ì´ ë„ˆë¬´ í¬ê±°ë‚˜ ë°ì´í„°ì— ì´ìƒì¹˜ê°€ ìˆìœ¼ë©´ ë°œìƒí•  ìˆ˜ ìˆìŠµë‹ˆë‹¤. `scaler.update()` ì „ `torch.nn.utils.clip_grad_norm_`ì„ ì¶”ê°€í•˜ê±°ë‚˜ LRì„ ì¤„ì´ì„¸ìš”.\n",
    "- **ë©”ëª¨ë¦¬ ë¶€ì¡±(OOM)**: ë°°ì¹˜ ì‚¬ì´ì¦ˆë¥¼ ì¤„ì´ê±°ë‚˜ `autocast`ê°€ ì œëŒ€ë¡œ ì ìš©ë˜ì—ˆëŠ”ì§€ í™•ì¸í•˜ì„¸ìš”. `Mixed Precision`ì€ ë©”ëª¨ë¦¬ ì‚¬ìš©ëŸ‰ì„ ì¤„ì—¬ì¤ë‹ˆë‹¤."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6abbe18",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
